{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqNsV3hChT4E"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,rotation_range=180,zoom_range=0.2,horizontal_flip=True)\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "0bguHKEUtVIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "x_train=train_datagen.flow_from_directory('/content/gdrive/My Drive/Dataset/train_set',target_size=(128,128),batch_size=32,class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hhp83NVtdRk",
        "outputId": "4b8756fd-bfc2-4496-fa82-41d27c0caa9e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Found 436 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test=test_datagen.flow_from_directory('/content/gdrive/My Drive/Dataset/test_set',target_size=(128,128),batch_size=32,class_mode='binary')"
      ],
      "metadata": {
        "id": "M3n460WFtiJX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f4689b1-13f3-43f0-b441-415a25e49fce"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 121 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()"
      ],
      "metadata": {
        "id": "WK8DhquWhhGj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Convolution2D(32,(3,3),input_shape=(128,128,3),activation='relu'))"
      ],
      "metadata": {
        "id": "tYWM3CA4ngZ_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(MaxPooling2D(pool_size=(2,2)))"
      ],
      "metadata": {
        "id": "SFjY8h4no6wc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Flatten())"
      ],
      "metadata": {
        "id": "fyn8GGbmpVD_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(150,activation='relu'))"
      ],
      "metadata": {
        "id": "h7CeeB5ep9lf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "ZS8R8Br6qdgd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer=\"adam\",metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "1F59XYEIrpwF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(x_train,steps_per_epoch=14,epochs=10,validation_data=x_test,validation_steps=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "em4-r-zRswIU",
        "outputId": "5e263f06-37f2-4d74-9a9e-b2582d87cde9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "14/14 [==============================] - 279s 20s/step - loss: 1.3991 - accuracy: 0.7546 - val_loss: 0.2404 - val_accuracy: 0.9091\n",
            "Epoch 2/10\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.3527 - accuracy: 0.8601 - val_loss: 0.0896 - val_accuracy: 0.9669\n",
            "Epoch 3/10\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.2285 - accuracy: 0.8991 - val_loss: 0.1806 - val_accuracy: 0.9256\n",
            "Epoch 4/10\n",
            "14/14 [==============================] - 27s 2s/step - loss: 0.2296 - accuracy: 0.9014 - val_loss: 0.1017 - val_accuracy: 0.9587\n",
            "Epoch 5/10\n",
            "14/14 [==============================] - 27s 2s/step - loss: 0.2330 - accuracy: 0.8945 - val_loss: 0.0695 - val_accuracy: 0.9669\n",
            "Epoch 6/10\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.1785 - accuracy: 0.9289 - val_loss: 0.0749 - val_accuracy: 0.9669\n",
            "Epoch 7/10\n",
            "14/14 [==============================] - 29s 2s/step - loss: 0.1741 - accuracy: 0.9381 - val_loss: 0.0600 - val_accuracy: 0.9835\n",
            "Epoch 8/10\n",
            "14/14 [==============================] - 27s 2s/step - loss: 0.1453 - accuracy: 0.9381 - val_loss: 0.0487 - val_accuracy: 0.9917\n",
            "Epoch 9/10\n",
            "14/14 [==============================] - 27s 2s/step - loss: 0.1628 - accuracy: 0.9289 - val_loss: 0.0498 - val_accuracy: 0.9835\n",
            "Epoch 10/10\n",
            "14/14 [==============================] - 27s 2s/step - loss: 0.1572 - accuracy: 0.9404 - val_loss: 0.0465 - val_accuracy: 0.9835\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8c55995550>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"forests.h5\")"
      ],
      "metadata": {
        "id": "UzK4SYn7Rv9F"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}